{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "weatherClassifierCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scottieballs/weather_classifier/blob/develop/weatherClassifierCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKyRMFIsWqPK",
        "colab_type": "text"
      },
      "source": [
        "# Weather Image Classifier\n",
        "\n",
        "This python notebook contains the implementation of a convolutional neural network (CNN)\n",
        "for classifiying weather images into the following six classes:\n",
        "\n",
        "1. Sunny\n",
        "1. Cloudy\n",
        "1. Rainy\n",
        "1. Foggy\n",
        "1. Other\n",
        "\n",
        "The dataset used is the Image2Weather dataset published by \n",
        "\n",
        "Wei-Ta Chu, Xiang-You Zheng, and Ding-Shiuan Ding, \"Camera as Weather Sensor: Estimating Weather Information from Single Images,\" Journal of Visual Communications and Image Representation, vol. 46, pp. 233-249, 2017.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KJTKtMaWqPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "84c4818c-1d37-462c-c26a-b755c17df2ac"
      },
      "source": [
        "# Import modules\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "import random\n",
        "import math\n",
        "import PIL\n",
        "import sys\n",
        "\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image\n",
        "\n",
        "print(tf.__version__)\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "# var startClickConnect = function startClickConnect(){\n",
        "#     var clickConnect = function clickConnect(){\n",
        "#         console.log(\"Connnect Clicked - Start\");\n",
        "#         document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "#         console.log(\"Connnect Clicked - End\"); \n",
        "#     };\n",
        "\n",
        "#     var intervalId = setInterval(clickConnect, 60000);\n",
        "\n",
        "#     var stopClickConnectHandler = function stopClickConnect() {\n",
        "#         console.log(\"Connnect Clicked Stopped - Start\");\n",
        "#         clearInterval(intervalId);\n",
        "#         console.log(\"Connnect Clicked Stopped - End\");\n",
        "#     };\n",
        "\n",
        "#     return stopClickConnectHandler;\n",
        "# };\n",
        "\n",
        "# var stopClickConnect = startClickConnect();\n",
        "\n",
        "# !pip install gputil\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import GPUtil as GPU\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#  process = psutil.Process(os.getpid())\n",
        "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm() "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxJevrHvYwqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d93073d2-eeaa-41d9-cb39-01711f8fb575"
      },
      "source": [
        "# Mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "cwd_path = os.path.abspath(os.getcwd())\n",
        "print(cwd_path)\n",
        "\n",
        "zip_file = cwd_path +'/gdrive/My\\ Drive/data/PreparedWeatherImages.zip'\n",
        "if (os.path.isdir('/tmp/data') == False):\n",
        "  os.mkdir('/tmp/data')\n",
        "!cp $zip_file '/tmp/data'\n",
        "\n",
        "# Unzip the dataset locally\n",
        "local_zip = '/tmp/data' + '/PreparedWeatherImages.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/data')\n",
        "zip_ref.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzGsNNJTWqPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the training and validation directories\n",
        "train_dir = '/tmp/data/WeatherImages'\n",
        "validation_dir = '/tmp/data/ValidationWeatherImages'\n",
        "\n",
        "# Set plot_vars = True if you want to see pictures of the data \n",
        "plot_vars = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t66fr0-PWqPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if plot_vars == True:\n",
        "  # Plot some of the images in the data set\n",
        "  %matplotlib inline\n",
        "\n",
        "  nrows = 1\n",
        "  ncols = 6\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "  image_list = []\n",
        "  for d in os.listdir(train_dir):\n",
        "      train_subdir = train_dir + '/' + d\n",
        "      filename = os.listdir(train_subdir)[0]\n",
        "      image_list.append(os.path.join(train_subdir, filename))\n",
        "\n",
        "  for img_path in image_list:\n",
        "      sp = plt.subplot(nrows, ncols, image_list.index(img_path)+1)\n",
        "      sp.axis('Off')\n",
        "      \n",
        "      img = mpimg.imread(img_path)\n",
        "      plt.imshow(img)\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtPgBnQqWqPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define callback class to stop training at 95 percent accuracy\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "checkpoint_path = cwd_path + '/gdrive/My Drive/data/training/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwGn6-v7pXZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7db15830-2ad9-4a7f-80ca-970613eca32b"
      },
      "source": [
        "use_transfer_learning = True\n",
        "\n",
        "# Transfer learning model using Inception\n",
        "pre_trained_model = InceptionV3(input_shape = (200, 200, 3), \n",
        "                                include_top = False, \n",
        "                                weights = \"imagenet\")\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = tf.keras.layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = tf.keras.layers.Dropout(0.2)(x)                  \n",
        "# Add a final softmax layer for multiclass classification\n",
        "x = tf.keras.layers.Dense(6, activation='softmax')(x)           \n",
        "\n",
        "transfer_learning_model = tf.keras.Model( pre_trained_model.input, x) \n",
        "\n",
        "transfer_learning_model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 10, 10, 768)\n",
            "Model: \"functional_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_663 (Conv2D)             (None, 99, 99, 32)   864         input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_663 (BatchN (None, 99, 99, 32)   96          conv2d_663[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_658 (Activation)     (None, 99, 99, 32)   0           batch_normalization_663[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_664 (Conv2D)             (None, 97, 97, 32)   9216        activation_658[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_664 (BatchN (None, 97, 97, 32)   96          conv2d_664[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_659 (Activation)     (None, 97, 97, 32)   0           batch_normalization_664[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_665 (Conv2D)             (None, 97, 97, 64)   18432       activation_659[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_665 (BatchN (None, 97, 97, 64)   192         conv2d_665[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_660 (Activation)     (None, 97, 97, 64)   0           batch_normalization_665[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling2D) (None, 48, 48, 64)   0           activation_660[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_666 (Conv2D)             (None, 48, 48, 80)   5120        max_pooling2d_31[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_666 (BatchN (None, 48, 48, 80)   240         conv2d_666[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_661 (Activation)     (None, 48, 48, 80)   0           batch_normalization_666[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_667 (Conv2D)             (None, 46, 46, 192)  138240      activation_661[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_667 (BatchN (None, 46, 46, 192)  576         conv2d_667[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_662 (Activation)     (None, 46, 46, 192)  0           batch_normalization_667[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling2D) (None, 22, 22, 192)  0           activation_662[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_671 (Conv2D)             (None, 22, 22, 64)   12288       max_pooling2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_671 (BatchN (None, 22, 22, 64)   192         conv2d_671[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_666 (Activation)     (None, 22, 22, 64)   0           batch_normalization_671[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_669 (Conv2D)             (None, 22, 22, 48)   9216        max_pooling2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_672 (Conv2D)             (None, 22, 22, 96)   55296       activation_666[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_669 (BatchN (None, 22, 22, 48)   144         conv2d_669[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_672 (BatchN (None, 22, 22, 96)   288         conv2d_672[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_664 (Activation)     (None, 22, 22, 48)   0           batch_normalization_669[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_667 (Activation)     (None, 22, 22, 96)   0           batch_normalization_672[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_63 (AveragePo (None, 22, 22, 192)  0           max_pooling2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_668 (Conv2D)             (None, 22, 22, 64)   12288       max_pooling2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_670 (Conv2D)             (None, 22, 22, 64)   76800       activation_664[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_673 (Conv2D)             (None, 22, 22, 96)   82944       activation_667[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_674 (Conv2D)             (None, 22, 22, 32)   6144        average_pooling2d_63[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_668 (BatchN (None, 22, 22, 64)   192         conv2d_668[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_670 (BatchN (None, 22, 22, 64)   192         conv2d_670[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_673 (BatchN (None, 22, 22, 96)   288         conv2d_673[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_674 (BatchN (None, 22, 22, 32)   96          conv2d_674[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_663 (Activation)     (None, 22, 22, 64)   0           batch_normalization_668[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_665 (Activation)     (None, 22, 22, 64)   0           batch_normalization_670[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_668 (Activation)     (None, 22, 22, 96)   0           batch_normalization_673[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_669 (Activation)     (None, 22, 22, 32)   0           batch_normalization_674[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 22, 22, 256)  0           activation_663[0][0]             \n",
            "                                                                 activation_665[0][0]             \n",
            "                                                                 activation_668[0][0]             \n",
            "                                                                 activation_669[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_678 (Conv2D)             (None, 22, 22, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_678 (BatchN (None, 22, 22, 64)   192         conv2d_678[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_673 (Activation)     (None, 22, 22, 64)   0           batch_normalization_678[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_676 (Conv2D)             (None, 22, 22, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_679 (Conv2D)             (None, 22, 22, 96)   55296       activation_673[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_676 (BatchN (None, 22, 22, 48)   144         conv2d_676[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_679 (BatchN (None, 22, 22, 96)   288         conv2d_679[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_671 (Activation)     (None, 22, 22, 48)   0           batch_normalization_676[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_674 (Activation)     (None, 22, 22, 96)   0           batch_normalization_679[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_64 (AveragePo (None, 22, 22, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_675 (Conv2D)             (None, 22, 22, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_677 (Conv2D)             (None, 22, 22, 64)   76800       activation_671[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_680 (Conv2D)             (None, 22, 22, 96)   82944       activation_674[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_681 (Conv2D)             (None, 22, 22, 64)   16384       average_pooling2d_64[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_675 (BatchN (None, 22, 22, 64)   192         conv2d_675[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_677 (BatchN (None, 22, 22, 64)   192         conv2d_677[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_680 (BatchN (None, 22, 22, 96)   288         conv2d_680[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_681 (BatchN (None, 22, 22, 64)   192         conv2d_681[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_670 (Activation)     (None, 22, 22, 64)   0           batch_normalization_675[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_672 (Activation)     (None, 22, 22, 64)   0           batch_normalization_677[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_675 (Activation)     (None, 22, 22, 96)   0           batch_normalization_680[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_676 (Activation)     (None, 22, 22, 64)   0           batch_normalization_681[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 22, 22, 288)  0           activation_670[0][0]             \n",
            "                                                                 activation_672[0][0]             \n",
            "                                                                 activation_675[0][0]             \n",
            "                                                                 activation_676[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_685 (Conv2D)             (None, 22, 22, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_685 (BatchN (None, 22, 22, 64)   192         conv2d_685[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_680 (Activation)     (None, 22, 22, 64)   0           batch_normalization_685[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_683 (Conv2D)             (None, 22, 22, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_686 (Conv2D)             (None, 22, 22, 96)   55296       activation_680[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_683 (BatchN (None, 22, 22, 48)   144         conv2d_683[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_686 (BatchN (None, 22, 22, 96)   288         conv2d_686[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_678 (Activation)     (None, 22, 22, 48)   0           batch_normalization_683[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_681 (Activation)     (None, 22, 22, 96)   0           batch_normalization_686[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_65 (AveragePo (None, 22, 22, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_682 (Conv2D)             (None, 22, 22, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_684 (Conv2D)             (None, 22, 22, 64)   76800       activation_678[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_687 (Conv2D)             (None, 22, 22, 96)   82944       activation_681[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_688 (Conv2D)             (None, 22, 22, 64)   18432       average_pooling2d_65[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_682 (BatchN (None, 22, 22, 64)   192         conv2d_682[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_684 (BatchN (None, 22, 22, 64)   192         conv2d_684[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_687 (BatchN (None, 22, 22, 96)   288         conv2d_687[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_688 (BatchN (None, 22, 22, 64)   192         conv2d_688[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_677 (Activation)     (None, 22, 22, 64)   0           batch_normalization_682[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_679 (Activation)     (None, 22, 22, 64)   0           batch_normalization_684[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_682 (Activation)     (None, 22, 22, 96)   0           batch_normalization_687[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_683 (Activation)     (None, 22, 22, 64)   0           batch_normalization_688[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 22, 22, 288)  0           activation_677[0][0]             \n",
            "                                                                 activation_679[0][0]             \n",
            "                                                                 activation_682[0][0]             \n",
            "                                                                 activation_683[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_690 (Conv2D)             (None, 22, 22, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_690 (BatchN (None, 22, 22, 64)   192         conv2d_690[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_685 (Activation)     (None, 22, 22, 64)   0           batch_normalization_690[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_691 (Conv2D)             (None, 22, 22, 96)   55296       activation_685[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_691 (BatchN (None, 22, 22, 96)   288         conv2d_691[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_686 (Activation)     (None, 22, 22, 96)   0           batch_normalization_691[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_689 (Conv2D)             (None, 10, 10, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_692 (Conv2D)             (None, 10, 10, 96)   82944       activation_686[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_689 (BatchN (None, 10, 10, 384)  1152        conv2d_689[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_692 (BatchN (None, 10, 10, 96)   288         conv2d_692[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_684 (Activation)     (None, 10, 10, 384)  0           batch_normalization_689[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_687 (Activation)     (None, 10, 10, 96)   0           batch_normalization_692[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling2D) (None, 10, 10, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 10, 10, 768)  0           activation_684[0][0]             \n",
            "                                                                 activation_687[0][0]             \n",
            "                                                                 max_pooling2d_33[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_697 (Conv2D)             (None, 10, 10, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_697 (BatchN (None, 10, 10, 128)  384         conv2d_697[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_692 (Activation)     (None, 10, 10, 128)  0           batch_normalization_697[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_698 (Conv2D)             (None, 10, 10, 128)  114688      activation_692[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_698 (BatchN (None, 10, 10, 128)  384         conv2d_698[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_693 (Activation)     (None, 10, 10, 128)  0           batch_normalization_698[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_694 (Conv2D)             (None, 10, 10, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_699 (Conv2D)             (None, 10, 10, 128)  114688      activation_693[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_694 (BatchN (None, 10, 10, 128)  384         conv2d_694[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_699 (BatchN (None, 10, 10, 128)  384         conv2d_699[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_689 (Activation)     (None, 10, 10, 128)  0           batch_normalization_694[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_694 (Activation)     (None, 10, 10, 128)  0           batch_normalization_699[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_695 (Conv2D)             (None, 10, 10, 128)  114688      activation_689[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_700 (Conv2D)             (None, 10, 10, 128)  114688      activation_694[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_695 (BatchN (None, 10, 10, 128)  384         conv2d_695[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_700 (BatchN (None, 10, 10, 128)  384         conv2d_700[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_690 (Activation)     (None, 10, 10, 128)  0           batch_normalization_695[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_695 (Activation)     (None, 10, 10, 128)  0           batch_normalization_700[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_66 (AveragePo (None, 10, 10, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_693 (Conv2D)             (None, 10, 10, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_696 (Conv2D)             (None, 10, 10, 192)  172032      activation_690[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_701 (Conv2D)             (None, 10, 10, 192)  172032      activation_695[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_702 (Conv2D)             (None, 10, 10, 192)  147456      average_pooling2d_66[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_693 (BatchN (None, 10, 10, 192)  576         conv2d_693[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_696 (BatchN (None, 10, 10, 192)  576         conv2d_696[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_701 (BatchN (None, 10, 10, 192)  576         conv2d_701[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_702 (BatchN (None, 10, 10, 192)  576         conv2d_702[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_688 (Activation)     (None, 10, 10, 192)  0           batch_normalization_693[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_691 (Activation)     (None, 10, 10, 192)  0           batch_normalization_696[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_696 (Activation)     (None, 10, 10, 192)  0           batch_normalization_701[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_697 (Activation)     (None, 10, 10, 192)  0           batch_normalization_702[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 10, 10, 768)  0           activation_688[0][0]             \n",
            "                                                                 activation_691[0][0]             \n",
            "                                                                 activation_696[0][0]             \n",
            "                                                                 activation_697[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_707 (Conv2D)             (None, 10, 10, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_707 (BatchN (None, 10, 10, 160)  480         conv2d_707[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_702 (Activation)     (None, 10, 10, 160)  0           batch_normalization_707[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_708 (Conv2D)             (None, 10, 10, 160)  179200      activation_702[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_708 (BatchN (None, 10, 10, 160)  480         conv2d_708[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_703 (Activation)     (None, 10, 10, 160)  0           batch_normalization_708[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_704 (Conv2D)             (None, 10, 10, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_709 (Conv2D)             (None, 10, 10, 160)  179200      activation_703[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_704 (BatchN (None, 10, 10, 160)  480         conv2d_704[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_709 (BatchN (None, 10, 10, 160)  480         conv2d_709[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_699 (Activation)     (None, 10, 10, 160)  0           batch_normalization_704[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_704 (Activation)     (None, 10, 10, 160)  0           batch_normalization_709[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_705 (Conv2D)             (None, 10, 10, 160)  179200      activation_699[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_710 (Conv2D)             (None, 10, 10, 160)  179200      activation_704[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_705 (BatchN (None, 10, 10, 160)  480         conv2d_705[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_710 (BatchN (None, 10, 10, 160)  480         conv2d_710[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_700 (Activation)     (None, 10, 10, 160)  0           batch_normalization_705[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_705 (Activation)     (None, 10, 10, 160)  0           batch_normalization_710[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_67 (AveragePo (None, 10, 10, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_703 (Conv2D)             (None, 10, 10, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_706 (Conv2D)             (None, 10, 10, 192)  215040      activation_700[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_711 (Conv2D)             (None, 10, 10, 192)  215040      activation_705[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_712 (Conv2D)             (None, 10, 10, 192)  147456      average_pooling2d_67[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_703 (BatchN (None, 10, 10, 192)  576         conv2d_703[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_706 (BatchN (None, 10, 10, 192)  576         conv2d_706[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_711 (BatchN (None, 10, 10, 192)  576         conv2d_711[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_712 (BatchN (None, 10, 10, 192)  576         conv2d_712[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_698 (Activation)     (None, 10, 10, 192)  0           batch_normalization_703[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_701 (Activation)     (None, 10, 10, 192)  0           batch_normalization_706[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_706 (Activation)     (None, 10, 10, 192)  0           batch_normalization_711[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_707 (Activation)     (None, 10, 10, 192)  0           batch_normalization_712[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 10, 10, 768)  0           activation_698[0][0]             \n",
            "                                                                 activation_701[0][0]             \n",
            "                                                                 activation_706[0][0]             \n",
            "                                                                 activation_707[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_717 (Conv2D)             (None, 10, 10, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_717 (BatchN (None, 10, 10, 160)  480         conv2d_717[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_712 (Activation)     (None, 10, 10, 160)  0           batch_normalization_717[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_718 (Conv2D)             (None, 10, 10, 160)  179200      activation_712[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_718 (BatchN (None, 10, 10, 160)  480         conv2d_718[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_713 (Activation)     (None, 10, 10, 160)  0           batch_normalization_718[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_714 (Conv2D)             (None, 10, 10, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_719 (Conv2D)             (None, 10, 10, 160)  179200      activation_713[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_714 (BatchN (None, 10, 10, 160)  480         conv2d_714[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_719 (BatchN (None, 10, 10, 160)  480         conv2d_719[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_709 (Activation)     (None, 10, 10, 160)  0           batch_normalization_714[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_714 (Activation)     (None, 10, 10, 160)  0           batch_normalization_719[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_715 (Conv2D)             (None, 10, 10, 160)  179200      activation_709[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_720 (Conv2D)             (None, 10, 10, 160)  179200      activation_714[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_715 (BatchN (None, 10, 10, 160)  480         conv2d_715[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_720 (BatchN (None, 10, 10, 160)  480         conv2d_720[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_710 (Activation)     (None, 10, 10, 160)  0           batch_normalization_715[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_715 (Activation)     (None, 10, 10, 160)  0           batch_normalization_720[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_68 (AveragePo (None, 10, 10, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_713 (Conv2D)             (None, 10, 10, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_716 (Conv2D)             (None, 10, 10, 192)  215040      activation_710[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_721 (Conv2D)             (None, 10, 10, 192)  215040      activation_715[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_722 (Conv2D)             (None, 10, 10, 192)  147456      average_pooling2d_68[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_713 (BatchN (None, 10, 10, 192)  576         conv2d_713[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_716 (BatchN (None, 10, 10, 192)  576         conv2d_716[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_721 (BatchN (None, 10, 10, 192)  576         conv2d_721[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_722 (BatchN (None, 10, 10, 192)  576         conv2d_722[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_708 (Activation)     (None, 10, 10, 192)  0           batch_normalization_713[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_711 (Activation)     (None, 10, 10, 192)  0           batch_normalization_716[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_716 (Activation)     (None, 10, 10, 192)  0           batch_normalization_721[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_717 (Activation)     (None, 10, 10, 192)  0           batch_normalization_722[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 10, 10, 768)  0           activation_708[0][0]             \n",
            "                                                                 activation_711[0][0]             \n",
            "                                                                 activation_716[0][0]             \n",
            "                                                                 activation_717[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_727 (Conv2D)             (None, 10, 10, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_727 (BatchN (None, 10, 10, 192)  576         conv2d_727[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_722 (Activation)     (None, 10, 10, 192)  0           batch_normalization_727[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_728 (Conv2D)             (None, 10, 10, 192)  258048      activation_722[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_728 (BatchN (None, 10, 10, 192)  576         conv2d_728[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_723 (Activation)     (None, 10, 10, 192)  0           batch_normalization_728[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_724 (Conv2D)             (None, 10, 10, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_729 (Conv2D)             (None, 10, 10, 192)  258048      activation_723[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_724 (BatchN (None, 10, 10, 192)  576         conv2d_724[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_729 (BatchN (None, 10, 10, 192)  576         conv2d_729[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_719 (Activation)     (None, 10, 10, 192)  0           batch_normalization_724[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_724 (Activation)     (None, 10, 10, 192)  0           batch_normalization_729[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_725 (Conv2D)             (None, 10, 10, 192)  258048      activation_719[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_730 (Conv2D)             (None, 10, 10, 192)  258048      activation_724[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_725 (BatchN (None, 10, 10, 192)  576         conv2d_725[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_730 (BatchN (None, 10, 10, 192)  576         conv2d_730[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_720 (Activation)     (None, 10, 10, 192)  0           batch_normalization_725[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_725 (Activation)     (None, 10, 10, 192)  0           batch_normalization_730[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_69 (AveragePo (None, 10, 10, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_723 (Conv2D)             (None, 10, 10, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_726 (Conv2D)             (None, 10, 10, 192)  258048      activation_720[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_731 (Conv2D)             (None, 10, 10, 192)  258048      activation_725[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_732 (Conv2D)             (None, 10, 10, 192)  147456      average_pooling2d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_723 (BatchN (None, 10, 10, 192)  576         conv2d_723[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_726 (BatchN (None, 10, 10, 192)  576         conv2d_726[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_731 (BatchN (None, 10, 10, 192)  576         conv2d_731[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_732 (BatchN (None, 10, 10, 192)  576         conv2d_732[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_718 (Activation)     (None, 10, 10, 192)  0           batch_normalization_723[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_721 (Activation)     (None, 10, 10, 192)  0           batch_normalization_726[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_726 (Activation)     (None, 10, 10, 192)  0           batch_normalization_731[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_727 (Activation)     (None, 10, 10, 192)  0           batch_normalization_732[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 10, 10, 768)  0           activation_718[0][0]             \n",
            "                                                                 activation_721[0][0]             \n",
            "                                                                 activation_726[0][0]             \n",
            "                                                                 activation_727[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 76800)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1024)         78644224    flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 1024)         0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 6)            6150        dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 87,625,638\n",
            "Trainable params: 78,650,374\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbZPjztCWqPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "30c704a0-3317-4ea1-c4d9-cbd490c47eda"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 198, 198, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 198, 198, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 196, 196, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 196, 196, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 98, 98, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 96, 96, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 96, 96, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 94, 94, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 94, 94, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 45, 45, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 45, 45, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 61952)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              63439872  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 6150      \n",
            "=================================================================\n",
            "Total params: 63,586,726\n",
            "Trainable params: 63,586,086\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoY6yOhfWqPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3bd922c-a9b3-44c2-d036-5c25d1c3a966"
      },
      "source": [
        "# Compile the model\n",
        "if use_transfer_learning:\n",
        "  transfer_learning_model.compile(loss='categorical_crossentropy',\n",
        "                                  optimizer=Adam(lr=0.001),\n",
        "                                  metrics=['accuracy'])\n",
        "  print(\"Using inception model\")\n",
        "else:\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=Adam(lr=0.001),\n",
        "                metrics=['accuracy'])\n",
        "  print(\"Using basic created model\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using inception model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jjJBmtqWqPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fbd7d176-ecfd-477e-d4e2-b5c511351288"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range=10,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1,\n",
        "                                   zoom_range=0.05,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (200, 200),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(200, 200),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 147041 images belonging to 6 classes.\n",
            "Found 36757 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njW5ah5wWqPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81dc9650-24e7-49fb-81c9-6c5076e148f7"
      },
      "source": [
        "if use_transfer_learning:\n",
        "  history = transfer_learning_model.fit(train_generator,\n",
        "                    steps_per_epoch = 100,\n",
        "                    epochs = 20,\n",
        "                    validation_data=validation_generator,\n",
        "                    verbose = 1,\n",
        "                    callbacks = [callbacks, cp_callback, lr_schedule])\n",
        "else:\n",
        "  history = model.fit(train_generator,\n",
        "                    steps_per_epoch = 100,\n",
        "                    epochs = 20,\n",
        "                    validation_data=validation_generator,\n",
        "                    verbose = 1,\n",
        "                    callbacks = [callbacks, cp_callback, lr_schedule])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.7913 - accuracy: 0.5838\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 388s 4s/step - loss: 3.7913 - accuracy: 0.5838 - val_loss: 0.7766 - val_accuracy: 0.6973\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.6974\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 369s 4s/step - loss: 0.7683 - accuracy: 0.6974 - val_loss: 0.7346 - val_accuracy: 0.7159\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7450 - accuracy: 0.7111\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 367s 4s/step - loss: 0.7450 - accuracy: 0.7111 - val_loss: 0.7058 - val_accuracy: 0.7257\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7288 - accuracy: 0.7202\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 362s 4s/step - loss: 0.7288 - accuracy: 0.7202 - val_loss: 0.6915 - val_accuracy: 0.7320\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7069 - accuracy: 0.7266\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 357s 4s/step - loss: 0.7069 - accuracy: 0.7266 - val_loss: 0.6784 - val_accuracy: 0.7386\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7026 - accuracy: 0.7262\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 358s 4s/step - loss: 0.7026 - accuracy: 0.7262 - val_loss: 0.6910 - val_accuracy: 0.7353\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.7262\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 355s 4s/step - loss: 0.7060 - accuracy: 0.7262 - val_loss: 0.6758 - val_accuracy: 0.7422\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6859 - accuracy: 0.7345\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 353s 4s/step - loss: 0.6859 - accuracy: 0.7345 - val_loss: 0.6699 - val_accuracy: 0.7402\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.7323\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 351s 4s/step - loss: 0.6941 - accuracy: 0.7323 - val_loss: 0.6666 - val_accuracy: 0.7415\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.7363\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 348s 3s/step - loss: 0.6767 - accuracy: 0.7363 - val_loss: 0.6664 - val_accuracy: 0.7409\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.7328\n",
            "Epoch 00011: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 356s 4s/step - loss: 0.6758 - accuracy: 0.7328 - val_loss: 0.6545 - val_accuracy: 0.7451\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6625 - accuracy: 0.7438\n",
            "Epoch 00012: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 351s 4s/step - loss: 0.6625 - accuracy: 0.7438 - val_loss: 0.6599 - val_accuracy: 0.7462\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.7437\n",
            "Epoch 00013: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 352s 4s/step - loss: 0.6763 - accuracy: 0.7437 - val_loss: 0.6675 - val_accuracy: 0.7381\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.7498\n",
            "Epoch 00014: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 360s 4s/step - loss: 0.6531 - accuracy: 0.7498 - val_loss: 0.6453 - val_accuracy: 0.7527\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.7489\n",
            "Epoch 00015: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 366s 4s/step - loss: 0.6507 - accuracy: 0.7489 - val_loss: 0.6457 - val_accuracy: 0.7504\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6574 - accuracy: 0.7406\n",
            "Epoch 00016: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 352s 4s/step - loss: 0.6574 - accuracy: 0.7406 - val_loss: 0.6390 - val_accuracy: 0.7540\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.7455\n",
            "Epoch 00017: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 352s 4s/step - loss: 0.6587 - accuracy: 0.7455 - val_loss: 0.6791 - val_accuracy: 0.7385\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.7457\n",
            "Epoch 00018: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 357s 4s/step - loss: 0.6564 - accuracy: 0.7457 - val_loss: 0.6391 - val_accuracy: 0.7567\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7492\n",
            "Epoch 00019: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 356s 4s/step - loss: 0.6462 - accuracy: 0.7492 - val_loss: 0.6345 - val_accuracy: 0.7537\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.7607\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "100/100 [==============================] - 355s 4s/step - loss: 0.6289 - accuracy: 0.7607 - val_loss: 0.6616 - val_accuracy: 0.7458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp66FPiAWqPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.save(cwd_path + '/gdrive/My Drive/Colab Notebooks/WeatherClassifier_inception_v31-08-2020.h5') "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oEt0mQqbi0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "f43bfd9b-f65c-4d14-f56f-2c140d1f432c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss' )\n",
        "plt.plot( epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b1224e51148f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_learning_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'History'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A641L7PrLE7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}