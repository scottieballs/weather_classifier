{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "weatherClassifierCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scottieballs/weather_classifier/blob/develop/weatherClassifierCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKyRMFIsWqPK",
        "colab_type": "text"
      },
      "source": [
        "# Weather Image Classifier\n",
        "\n",
        "This python notebook contains the implementation of a convolutional neural network (CNN)\n",
        "for classifiying weather images into the following six classes:\n",
        "\n",
        "1. Sunny\n",
        "1. Cloudy\n",
        "1. Rainy\n",
        "1. Foggy\n",
        "1. Other\n",
        "\n",
        "The dataset used is the Image2Weather dataset published by \n",
        "\n",
        "Wei-Ta Chu, Xiang-You Zheng, and Ding-Shiuan Ding, \"Camera as Weather Sensor: Estimating Weather Information from Single Images,\" Journal of Visual Communications and Image Representation, vol. 46, pp. 233-249, 2017.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KJTKtMaWqPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c81688c3-8978-4000-c28f-6825b0204422"
      },
      "source": [
        "# Import modules\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "import math\n",
        "import PIL\n",
        "import sys\n",
        "\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image\n",
        "\n",
        "print(tf.__version__)\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "# var startClickConnect = function startClickConnect(){\n",
        "#     var clickConnect = function clickConnect(){\n",
        "#         console.log(\"Connnect Clicked - Start\");\n",
        "#         document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "#         console.log(\"Connnect Clicked - End\"); \n",
        "#     };\n",
        "\n",
        "#     var intervalId = setInterval(clickConnect, 60000);\n",
        "\n",
        "#     var stopClickConnectHandler = function stopClickConnect() {\n",
        "#         console.log(\"Connnect Clicked Stopped - Start\");\n",
        "#         clearInterval(intervalId);\n",
        "#         console.log(\"Connnect Clicked Stopped - End\");\n",
        "#     };\n",
        "\n",
        "#     return stopClickConnectHandler;\n",
        "# };\n",
        "\n",
        "# var stopClickConnect = startClickConnect();\n",
        "\n",
        "# !pip install gputil\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import GPUtil as GPU\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#  process = psutil.Process(os.getpid())\n",
        "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxJevrHvYwqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0023c25d-3eb5-4b44-bd08-816ea44f7591"
      },
      "source": [
        "# Mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "cwd_path = os.path.abspath(os.getcwd())\n",
        "print(cwd_path)\n",
        "\n",
        "zip_file = cwd_path +'/gdrive/My\\ Drive/data/PreparedWeatherImages.zip'\n",
        "if (os.path.isdir('/tmp/data') == False):\n",
        "  os.mkdir('/tmp/data')\n",
        "!cp $zip_file '/tmp/data'\n",
        "\n",
        "# Unzip the dataset locally\n",
        "local_zip = '/tmp/data' + '/PreparedWeatherImages.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/data')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzGsNNJTWqPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the training and validation directories\n",
        "train_dir = '/tmp/data/WeatherImages'\n",
        "validation_dir = '/tmp/data/ValidationWeatherImages'\n",
        "\n",
        "# Set plot_vars = True if you want to see pictures of the data \n",
        "plot_vars = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t66fr0-PWqPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if plot_vars == True:\n",
        "  # Plot some of the images in the data set\n",
        "  %matplotlib inline\n",
        "\n",
        "  nrows = 1\n",
        "  ncols = 6\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "  image_list = []\n",
        "  for d in os.listdir(train_dir):\n",
        "      train_subdir = train_dir + '/' + d\n",
        "      filename = os.listdir(train_subdir)[0]\n",
        "      image_list.append(os.path.join(train_subdir, filename))\n",
        "\n",
        "  for img_path in image_list:\n",
        "      sp = plt.subplot(nrows, ncols, image_list.index(img_path)+1)\n",
        "      sp.axis('Off')\n",
        "      \n",
        "      img = mpimg.imread(img_path)\n",
        "      plt.imshow(img)\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtPgBnQqWqPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define callback class to stop training at 95 percent accuracy\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "checkpoint_path = cwd_path + '/gdrive/My Drive/data/training/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbZPjztCWqPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "30c704a0-3317-4ea1-c4d9-cbd490c47eda"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 198, 198, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 198, 198, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 196, 196, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 196, 196, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 98, 98, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 96, 96, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 96, 96, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 94, 94, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 94, 94, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 45, 45, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 45, 45, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 61952)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              63439872  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 6150      \n",
            "=================================================================\n",
            "Total params: 63,586,726\n",
            "Trainable params: 63,586,086\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoY6yOhfWqPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.001),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jjJBmtqWqPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b7fc106-5e7f-4aff-e813-4ef045238c8f"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range=10,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1,\n",
        "                                   zoom_range=0.05,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (200, 200),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(200, 200),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 147041 images belonging to 6 classes.\n",
            "Found 36757 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njW5ah5wWqPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c259d20-9393-4642-8b25-8d4521288f8f"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch = 450,\n",
        "                    epochs = 15,\n",
        "                    validation_data=validation_generator,\n",
        "                    verbose = 1,\n",
        "                    callbacks = [callbacks, cp_callback])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.8009 - accuracy: 0.6984\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 937s 2s/step - loss: 0.8009 - accuracy: 0.6984 - val_loss: 0.8329 - val_accuracy: 0.6786\n",
            "Epoch 2/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.7333 - accuracy: 0.7272\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 998s 2s/step - loss: 0.7333 - accuracy: 0.7272 - val_loss: 0.8073 - val_accuracy: 0.6940\n",
            "Epoch 3/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.7446\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 994s 2s/step - loss: 0.7059 - accuracy: 0.7446 - val_loss: 0.7394 - val_accuracy: 0.7124\n",
            "Epoch 4/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.7477\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 963s 2s/step - loss: 0.6926 - accuracy: 0.7477 - val_loss: 0.8694 - val_accuracy: 0.6791\n",
            "Epoch 5/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.7459\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 936s 2s/step - loss: 0.6968 - accuracy: 0.7459 - val_loss: 0.9962 - val_accuracy: 0.6312\n",
            "Epoch 6/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.7544\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 935s 2s/step - loss: 0.6757 - accuracy: 0.7544 - val_loss: 0.7115 - val_accuracy: 0.7268\n",
            "Epoch 7/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.7584\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 930s 2s/step - loss: 0.6651 - accuracy: 0.7584 - val_loss: 1.5344 - val_accuracy: 0.3614\n",
            "Epoch 8/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.7563\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 930s 2s/step - loss: 0.6670 - accuracy: 0.7563 - val_loss: 1.2980 - val_accuracy: 0.5218\n",
            "Epoch 9/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6548 - accuracy: 0.7624\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 921s 2s/step - loss: 0.6548 - accuracy: 0.7624 - val_loss: 0.7923 - val_accuracy: 0.7051\n",
            "Epoch 10/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.7641\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 918s 2s/step - loss: 0.6510 - accuracy: 0.7641 - val_loss: 0.7404 - val_accuracy: 0.7272\n",
            "Epoch 11/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.7686\n",
            "Epoch 00011: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 923s 2s/step - loss: 0.6362 - accuracy: 0.7686 - val_loss: 0.6807 - val_accuracy: 0.7406\n",
            "Epoch 12/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6387 - accuracy: 0.7679\n",
            "Epoch 00012: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 917s 2s/step - loss: 0.6387 - accuracy: 0.7679 - val_loss: 0.8499 - val_accuracy: 0.6523\n",
            "Epoch 13/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7637\n",
            "Epoch 00013: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 923s 2s/step - loss: 0.6462 - accuracy: 0.7637 - val_loss: 1.7505 - val_accuracy: 0.3933\n",
            "Epoch 14/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6323 - accuracy: 0.7677\n",
            "Epoch 00014: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 913s 2s/step - loss: 0.6323 - accuracy: 0.7677 - val_loss: 0.8703 - val_accuracy: 0.6830\n",
            "Epoch 15/15\n",
            "450/450 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.7756\n",
            "Epoch 00015: saving model to /content/gdrive/My Drive/data/training/cp.ckpt\n",
            "450/450 [==============================] - 908s 2s/step - loss: 0.6170 - accuracy: 0.7756 - val_loss: 0.8046 - val_accuracy: 0.7342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp66FPiAWqPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.save(cwd_path + '/gdrive/My Drive/Colab Notebooks/WeatherClassifier_model_v28-08-2020.h5') "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oEt0mQqbi0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}